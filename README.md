# Linear Regression Lab

## Assignment #1

### Goals
- Understand basic descent methods by applying them to a toy model.
- Apply style rules for coding.

### Questions
1. Write a function leastsquares_gd that takes y and X and returns the least squares estimate calculated with gradient descent. Compare the outcomes of this function with the ones of the lm package and the ones from direct calculation. What is the influence of the stepsize? What is the influence of the number of gradient descent iterations? Are these two quantities connected?
2. Write a function leastsquares_gd_bt that complements leastsquares_gd with a backtracking rule.
3. Write a function leastsquares_cd that computes the least-squares estimator via coordinate descent. Compare all methods in terms of accuracy and speed.
4. Create a fuction leastsquares_cd_pr that computes the least-squares estimator via coordinate descent and pre-computes as many quantities as possible. 

## Licensing
Contact author for licensing options

## Author
- **Johannes Lederer** - *Assistant Professor, University of Washington* 